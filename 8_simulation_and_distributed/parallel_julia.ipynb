{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Julia\n",
    "\n",
    "To run multiple local processes in parallel, we first need to tell julia how many processes we want to add. This should be less than or equal to the effective number of processors our machine has. That number is fixed for a laptop (probably 4 or 8), but we can set it on Engaging with the \"cpus-per-task\" parameter. There are two ways to do this.\n",
    "\n",
    "1. Launch julia with the \"-p\" flag: ```julia -p 3 my_script.jl```\n",
    "2. Add processes while julia is already running: ```addprocs(3)``` (Note: do this before running any other commands to ensure your modules are loaded across all of the worker processes.)\n",
    "\n",
    "Both of these will launch 4 total processes, the master and then 3 additional worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia provides low-level functions for parallel computing. These allow us to specify which process evaluates each expression. The documentation can be found here:\n",
    "https://docs.julialang.org/en/stable/manual/parallel-computing/\n",
    "\n",
    "For much of what we want to do, this granular level of control is unnecessary. Instead, we can use some high-level functions and let julia figure out how to distribute the work amongst the various processes.\n",
    "\n",
    "There are two high-level functions we will  use:\n",
    "\n",
    "1. ```@parallel for```\n",
    "2. ```pmap```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the following problem:\n",
    "\n",
    "A random walker takes steps according to a ten thousand step Bernoulli process with parameter 0.001, each step being +1 or -1 with equal probability. Any time the walker takes a step, we have the chance to bet for/against it. If we bet for it, we will get the difference between the walker's final position and the current position. If we bet against it, we will get the difference between the walker's current position and the walker's final position.\n",
    "\n",
    "We want to evaluate the expected profit of the following strategy:\n",
    "\n",
    "1. If the walker is at or below -a, bet in favor of the walker\n",
    "2. If the walker is at or above +a, bet against the walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's write a function to simulate a single trial of this game\n",
    "function simulate_path(a)\n",
    "    T = 10000\n",
    "    p = 0.001\n",
    "    profit = 0\n",
    "    walker_position = 0\n",
    "    n_bets_for = 0\n",
    "    n_bets_against = 0\n",
    "    just_stepped = false\n",
    "    for i in 1:T\n",
    "        step = rand()\n",
    "        if \n",
    "            \n",
    "        elseif \n",
    "            \n",
    "        else\n",
    "            \n",
    "        end\n",
    "        if \n",
    "            \n",
    "        elseif \n",
    "            \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return profit\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's write a function to run a million trials of this simulation\n",
    "function serial_simulate(a)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time serial_simulate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not let's try it with a parallel for loop\n",
    "function parallel_simulate(a)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time parallel_simulate(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the + sign is called the reduction operator. It's not required for parallel for loops, but I recommend always including one. It can be any operation that can be recursively applied pairwise. The order in which the iterations of the loop will execute is not guaranteed, so it should be commutative. If we need the entire vector of results, we can use the ```vcat``` reduction operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables\n",
    "\n",
    "If the expressions executed within the parallel for loop reference global variables (i.e. variables defined outside of a function or class), then each worker process will be passed a copy of that variable. If these variables are only needed as read-only variables, then this is okay. However, unnecessarily passing large chunks of memory between processes can significantly slow down your script. Attempting to modify the contents of a global variable within a parallel for loop will not have the intended effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't do this\n",
    "a = zeros(3)\n",
    "@parallel for i = 1:3\n",
    "    a[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fetch(@spawnat 2 getfield(Main,:a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to avoid using global variables whenver possible. However, if you do need a shared variable that all processes can write to, you can use the ```SharedArray``` type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```pmap```\n",
    "\n",
    "Parallel for loops are optimized for the setting in which each iteration of the loop only does a small amount of work. In contrast, ```pmap``` is optimized for the setting in which each function call does a large amount of work. Let's consider the same example as before, but we now wish to evaluate the expected profit of a variety of different thresholds.\n",
    "\n",
    "Bonus! Why is that? For parallel for loops, the work is divided up immediately, so each worker process will evaluate the same number of iterations. With ```pmap``` a queue is formed and jobs are distributed to the workers as they complete their prior jobs. If there are only a few jobs, there will likely be some variation in the amount of time they will take to execute. It's less efficient to pre-assign them to worker processes than to dynamically asssign them. However, if there are many jobs, the time to complete a subset of 333,333 of them will have little variation, so the overhead of dynamic job assignment is less efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comment: if a function takes multiple arguments, each set of elements as a tuple and pass an array of tuples as the second arguments to ```pmap```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
